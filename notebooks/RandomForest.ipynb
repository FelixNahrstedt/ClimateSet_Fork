{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from typing import Dict, Optional, List, Callable, Tuple, Union\n",
    "\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/home/mila/v/venkatesh.ramesh/scratch/causal_data/inputs/input4mips'\n",
    "target_dir = '/home/mila/v/venkatesh.ramesh/scratch/causal_data/targets/CMIP6'\n",
    "\n",
    "models = ['NorESM2-LM']\n",
    "fire_type = 'all-fires'\n",
    "variables = ['pr']\n",
    "train_experiments = [ \"ssp585\", \"ssp126\", \"ssp370\"] \n",
    "test_experiments = [\"ssp245\"]\n",
    "input_gases = ['BC_sum', 'CH4_sum', 'CO2_sum', 'SO2_sum']\n",
    "total_ensembles = 1 #-1 for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which variable to load and prepare the data for it.\n",
    "# Can reuse the data-prep code from the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(mode: str = 'train') -> tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    X = get_input_data(input_dir, mode)\n",
    "    y = get_output_data(target_dir, mode)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_data_npz(path: str): #If np data already exists\n",
    "    X_train, y_train = np.load(os.path.join(base_dir, ''))\n",
    "    X_test, y_test = np.load(os.path.join(base_dir, ''))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def get_input_data(path: str, mode: str):\n",
    "    BC = []\n",
    "    CH4 = []\n",
    "    CO2 = []\n",
    "    SO2 = []\n",
    "    \n",
    "    if mode == 'train':      \n",
    "        experiments = train_experiments\n",
    "    elif mode == 'test':\n",
    "        experiments = test_experiments\n",
    "        \n",
    "    for exp in experiments:\n",
    "        for gas in input_gases:\n",
    "            var_dir = os.path.join(path, exp, gas, 'map_250_km/mon')\n",
    "            files = glob.glob(var_dir + '/**/*.nc', recursive=True)\n",
    "\n",
    "            for f in files:\n",
    "                if gas == 'BC_sum' and fire_type in f:\n",
    "                    BC.append(f)\n",
    "            for f in files:\n",
    "                if gas == 'CH4_sum' and fire_type in f:\n",
    "                    CH4.append(f)\n",
    "            for f in files:\n",
    "                if gas == 'BC_sum' and fire_type in f:\n",
    "                    SO2.append(f)\n",
    "            for f in files:\n",
    "                if gas == 'CO2_sum':\n",
    "                    CO2.append(f)\n",
    "\n",
    "    BC_data = xr.open_mfdataset(BC, concat_dim='time', combine='nested').compute().to_array().to_numpy()\n",
    "    CH4_data = xr.open_mfdataset(CH4, concat_dim='time', combine='nested').compute().to_array().to_numpy()\n",
    "    CO2_data = xr.open_mfdataset(CO2, concat_dim='time', combine='nested').compute().to_array().to_numpy()\n",
    "    SO2_data = xr.open_mfdataset(SO2, concat_dim='time', combine='nested').compute().to_array().to_numpy()\n",
    "\n",
    "    merged_data = np.concatenate((BC_data, CH4_data, CO2_data, SO2_data), axis=0)\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "def get_output_data(path: str, mode: str):\n",
    "    nc_files = []\n",
    "    \n",
    "    if mode == 'train':\n",
    "        experiments = train_experiments\n",
    "    elif mode == 'test':\n",
    "        experiments = test_experiments\n",
    "        \n",
    "    for mod in models:\n",
    "\n",
    "        model_dir = os.path.join(path, mod)\n",
    "        ensembles = os.listdir(model_dir)\n",
    "\n",
    "        if total_ensembles == 1:\n",
    "            ensembles = ensembles[0]\n",
    "        \n",
    "        exp_counter = 0\n",
    "        for exp in experiments:\n",
    "            for var in variables:\n",
    "                var_dir = os.path.join(path, mod, ensembles, exp, var, '250_km/mon')\n",
    "                files = glob.glob(var_dir + '/**/*.nc', recursive=True)\n",
    "                nc_files += files\n",
    "        \n",
    "            if exp_counter == 0:\n",
    "                dataset = xr.open_mfdataset(nc_files).compute().to_array().to_numpy()\n",
    "        \n",
    "            else: #concatenate dataset in time dimension\n",
    "                other_experiment = xr.open_mfdataset(nc_files).compute().to_array().to_numpy()\n",
    "                dataset = np.concatenate((dataset, other_experiment), axis=1)\n",
    "                \n",
    "                \n",
    "            exp_counter += 1\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3096, 96, 144) (1, 3096, 96, 144) (4, 1032, 96, 144) (1, 1032, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3096, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "X_stat = X_train.copy()\n",
    "print(X_stat.shape)\n",
    "\n",
    "vars_mean = np.mean(X_stat, axis=(1, 2, 3))\n",
    "vars_std = np.std(X_stat, axis=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.915785021941452e-12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(vars_std) + 1e-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars_mean = np.expand_dims(vars_mean, (1, 2, 3))\n",
    "# vars_std = np.expand_dims(vars_std, (1, 2, 3))\n",
    "\n",
    "print(vars_mean.shape, vars_std.shape)\n",
    "\n",
    "print(vars_mean, vars_std)\n",
    "\n",
    "input_stats = np.concatenate((np.expand_dims(vars_mean, (-1, 1, 2, 3)), np.expand_dims(vars_std, (-1, 1, 2, 3))), axis=-1)\n",
    "\n",
    "input_stats\n",
    "\n",
    "x = np.array([3.1055716e-13, 1.9952876e-11, 2.7081224e-09, 3.1055716e-13])\n",
    "\n",
    "x = np.expand_dims(x, (1, 2, 3))\n",
    "print(x.shape)\n",
    "\n",
    "X_norm = (X_stat - vars_mean)/ vars_std\n",
    "\n",
    "print(X_norm.shape)\n",
    "\n",
    "y_train.shape\n",
    "\n",
    "out_mean = np.mean(y_train, axis=(1, 2, 3))\n",
    "out_std = np.mean(y_train, axis=(1, 2, 3))\n",
    "\n",
    "print(out_mean, out_std)\n",
    "\n",
    "y_norm = (y_train - out_mean)/(out_std)\n",
    "\n",
    "# (v - v.min()) / (v.max() - v.min())\n",
    "\n",
    "z = np.zeros((258, 12, 4, 96, 144))\n",
    "\n",
    "z = np.moveaxis(z, 2, 0)\n",
    "print(z.shape)\n",
    "\n",
    "z_max = np.min(z, (1, 2, 3, 4))\n",
    "\n",
    "print(z_max.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Parameters & HyperParameters (same as climatebench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**parameters & hyperparameters\n",
    "\n",
    "RSCV= True\n",
    "path_output='output_path/output.nc'\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5,55, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 8, 12]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg0 = RandomForestRegressor(random_state=0)\n",
    "rf_random0 = RandomizedSearchCV(estimator = reg0, param_distributions = random_grid, n_iter = 10, cv = 2, verbose=2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032, 4, 96, 144) (1032, 1, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.moveaxis(X_test, 0, 1)\n",
    "y_test = np.moveaxis(y_test, 0, 1)\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "y_test = y_test.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032, 55296) (1032, 13824)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/home/mila/v/venkatesh.ramesh/env_emulator/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=12, min_samples_split=5, n_estimators=300; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=35, max_features=sqrt, min_samples_leaf=8, min_samples_split=25, n_estimators=150; total time=  11.9s\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=15, n_estimators=150; total time= 4.0min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=8, min_samples_split=5, n_estimators=200; total time= 5.4min\n"
     ]
    }
   ],
   "source": [
    "rf_pr = rf_random0.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=12, min_samples_split=5, n_estimators=300; total time=  22.5s\n",
      "[CV] END bootstrap=False, max_depth=35, max_features=sqrt, min_samples_leaf=8, min_samples_split=25, n_estimators=150; total time=  16.1s\n",
      "[CV] END bootstrap=False, max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=15, n_estimators=150; total time= 4.3min\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=8, min_samples_split=5, n_estimators=200; total time= 5.7min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=12, min_samples_split=15, n_estimators=100; total time= 2.7min\n",
      "[CV] END bootstrap=False, max_depth=55, max_features=sqrt, min_samples_leaf=4, min_samples_split=15, n_estimators=100; total time=   8.1s\n",
      "[CV] END bootstrap=False, max_depth=55, max_features=sqrt, min_samples_leaf=4, min_samples_split=15, n_estimators=100; total time=  11.0s\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=8, min_samples_split=10, n_estimators=150; total time= 4.3min\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=12, min_samples_split=15, n_estimators=100; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=55, max_features=auto, min_samples_leaf=12, min_samples_split=25, n_estimators=200; total time= 3.2min\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=12, min_samples_split=15, n_estimators=100; total time= 2.9min\n",
      "[CV] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=8, min_samples_split=10, n_estimators=150; total time= 4.0min\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=15, n_estimators=250; total time=  14.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=15, n_estimators=250; total time=  18.7s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=12, min_samples_split=15, n_estimators=100; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=55, max_features=auto, min_samples_leaf=12, min_samples_split=25, n_estimators=200; total time= 3.4min\n"
     ]
    }
   ],
   "source": [
    "print(rf_pr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3096, 96, 144) (1, 3096, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096, 4, 96, 144) (3096, 1, 96, 144)\n",
      "(3096, 55296) (3096, 13824)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.moveaxis(X_train, 0, 1)\n",
    "y_train = np.moveaxis(y_train, 0, 1)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "y_train = y_train.reshape(y_train.shape[0], -1)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_pr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096, 13824)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(3096, 1, 96, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8836844003928504e-05"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg0 = RandomForestRegressor(random_state=0)\n",
    "# reg1 = RandomForestRegressor(random_state=0)\n",
    "# reg2 = RandomForestRegressor(random_state=0)\n",
    "# reg3 = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# if(RSCV==False):\n",
    "#     rf_tas = reg0.fit(X_train_tas,y_train_tas)\n",
    "#     rf_pr = reg1.fit(X_train_pr,y_train_pr)\n",
    "#     rf_pr90 = reg2.fit(X_train_pr90,y_train_pr90)\n",
    "#     rf_dtr = reg3.fit(X_train_dtr,y_train_dtr)\n",
    "# else:\n",
    "#     rf_random0 = RandomizedSearchCV(estimator = reg0, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "#     rf_random1 = RandomizedSearchCV(estimator = reg1, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "#     rf_random2 = RandomizedSearchCV(estimator = reg2, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "#     rf_random3 = RandomizedSearchCV(estimator = reg3, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "#     #n_iter = 29\n",
    "    \n",
    "#     rf_tas = rf_random0.fit(X_train_tas,y_train_tas)\n",
    "#     rf_pr = rf_random1.fit(X_train_pr,y_train_pr)\n",
    "#     rf_pr90 = rf_random2.fit(X_train_pr90,y_train_pr90)\n",
    "#     rf_dtr = rf_random3.fit(X_train_dtr,y_train_dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulator",
   "language": "python",
   "name": "emulator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
