{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from typing import Dict, Optional, List, Callable, Tuple, Union\n",
    "\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from eofs.xarray import Eof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/home/mila/v/venkatesh.ramesh/scratch/causal_data/inputs/input4mips'\n",
    "target_dir = '/home/mila/v/venkatesh.ramesh/scratch/causal_data/targets/CMIP6'\n",
    "\n",
    "models = ['NorESM2-LM']\n",
    "fire_type = 'all-fires'\n",
    "variables = ['pr']\n",
    "train_experiments = [\"ssp126\"] #[ \"ssp585\", \"ssp126\", \"ssp370\"]\n",
    "test_experiments = [\"ssp245\"]\n",
    "input_gases = ['BC_sum', 'CH4_sum', 'CO2_sum', 'SO2_sum']\n",
    "total_ensembles = 1 #-1 for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which variable to load and prepare the data for it.\n",
    "# Can reuse the data-prep code from the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(mode: str = 'train') -> tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    X = get_input_data(input_dir, mode)\n",
    "    y = get_output_data(target_dir, mode)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_data_npz(path: str): #If np data already exists\n",
    "    X_train, y_train = np.load(os.path.join(base_dir, ''))\n",
    "    X_test, y_test = np.load(os.path.join(base_dir, ''))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def get_input_data(path: str, mode: str) -> List['str']:\n",
    "    BC = []\n",
    "    CH4 = []\n",
    "    CO2 = []\n",
    "    SO2 = []\n",
    "    \n",
    "    if mode == 'train':      \n",
    "        experiments = train_experiments\n",
    "    elif mode == 'test':\n",
    "        experiments = test_experiments\n",
    "        \n",
    "    for exp in experiments:\n",
    "        for gas in input_gases:\n",
    "            var_dir = os.path.join(path, exp, gas, 'map_250_km/mon')\n",
    "            files = glob.glob(var_dir + '/**/*.nc', recursive=True)\n",
    "\n",
    "            for f in files:\n",
    "                if gas == 'BC_sum' and fire_type in f:\n",
    "                    BC.append(f)\n",
    "            for f in files:\n",
    "                if gas == 'CH4_sum' and fire_type in f:\n",
    "                    CH4.append(f)\n",
    "            for f in files:\n",
    "                if gas == 'BC_sum' and fire_type in f:\n",
    "                    SO2.append(f)\n",
    "            for f in files:\n",
    "                if gas == 'CO2_sum':\n",
    "                    CO2.append(f)\n",
    "\n",
    "    BC_data = xr.open_mfdataset(BC).compute().to_array().to_numpy()\n",
    "    CH4_data = xr.open_mfdataset(CH4).compute().to_array().to_numpy()\n",
    "    CO2_data = xr.open_mfdataset(CO2).compute().to_array().to_numpy()\n",
    "    SO2_data = xr.open_mfdataset(SO2).compute().to_array().to_numpy()\n",
    "\n",
    "#         merged_data = xr.concat((BC_data, CH4_data, CO2_data, SO2_data), dim=0)\n",
    "    merged_data = np.concatenate((BC_data, CH4_data, CO2_data, SO2_data), axis=0)\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "def get_output_data(path: str, mode: str) -> List['str']:\n",
    "    nc_files = []\n",
    "    \n",
    "    if mode == 'train':\n",
    "        experiments = train_experiments\n",
    "    elif mode == 'test':\n",
    "        experiments = test_experiments\n",
    "        \n",
    "    for mod in models:\n",
    "\n",
    "        model_dir = os.path.join(path, mod)\n",
    "        ensembles = os.listdir(model_dir)\n",
    "\n",
    "        if total_ensembles == 1:\n",
    "            ensembles = ensembles[0]\n",
    "\n",
    "        for exp in experiments:\n",
    "            for var in variables:\n",
    "                var_dir = os.path.join(path, mod, ensembles, exp, var, '250_km/mon')\n",
    "#                 print(os.path.join(path, mod, ensembles, exp, var,'250_km/mon'))\n",
    "                files = glob.glob(var_dir + '/**/*.nc', recursive=True)\n",
    "                nc_files += files\n",
    "    \n",
    "    return xr.open_mfdataset(nc_files).compute().to_array().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1032, 96, 144) (1, 1032, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_data('test')\n",
    "print(X_train.shape, y_train.shape)\n",
    "# data, files = load_data('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Parameters & HyperParameters (same as climatebench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**parameters & hyperparameters\n",
    "\n",
    "RSCV= True\n",
    "path_output='output_path/output.nc'\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5,55, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 8, 12]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg0 = RandomForestRegressor(random_state=0)\n",
    "reg1 = RandomForestRegressor(random_state=0)\n",
    "reg2 = RandomForestRegressor(random_state=0)\n",
    "reg3 = RandomForestRegressor(random_state=0)\n",
    "\n",
    "if(RSCV==False):\n",
    "    rf_tas = reg0.fit(X_train_tas,y_train_tas)\n",
    "    rf_pr = reg1.fit(X_train_pr,y_train_pr)\n",
    "    rf_pr90 = reg2.fit(X_train_pr90,y_train_pr90)\n",
    "    rf_dtr = reg3.fit(X_train_dtr,y_train_dtr)\n",
    "else:\n",
    "    rf_random0 = RandomizedSearchCV(estimator = reg0, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "    rf_random1 = RandomizedSearchCV(estimator = reg1, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "    rf_random2 = RandomizedSearchCV(estimator = reg2, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "    rf_random3 = RandomizedSearchCV(estimator = reg3, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "    #n_iter = 29\n",
    "    \n",
    "    rf_tas = rf_random0.fit(X_train_tas,y_train_tas)\n",
    "    rf_pr = rf_random1.fit(X_train_pr,y_train_pr)\n",
    "    rf_pr90 = rf_random2.fit(X_train_pr90,y_train_pr90)\n",
    "    rf_dtr = rf_random3.fit(X_train_dtr,y_train_dtr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulator",
   "language": "python",
   "name": "emulator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
