#!/bin/bash

#SBATCH --job-name="SC6-basetest-convlstm"

#SBATCH --nodes=1

#SBATCH --partition=main

#SBATCH --gpus-per-node=a100:1 --constraint="dgx&ampere"       # specify gpu

#SBATCH --ntasks-per-node=1

#SBATCH --cpus-per-task=2       # cpu-cores per task (>1 if multi-threaded tasks)

#SBATCH --mem=16G               # memory per node (4G per cpu-core is default)

#SBATCH --time=00:30:00                                  # set runtime

#SBATCH -o /home/mila/f/felix-andreas.nahrstedt/Slurm/TEST-convlstm2.out        # set log dir to home

EXP_NAME=$1
DL_FRAMEWORK="torch"

echo "Beginning experiment $EXP_NAME."

# 1. Load Python

module load python/3.10
export PYTHONPATH=$(pwd)
echo $PYTHONPATH

# 2. Load DL Framework

if [[ $DL_FRAMEWORK == "torch" ]]; then

    module load cuda/10.0/cudnn/7.6
    #module load python/3.7/cuda/11.1/cudnn/8.0/pytorch/1.8.1
    
fi

# 3. Create or Set Up Environment
deactivate

source env_new_emulator/bin/activate

python -m venv env_new_emulator
source env_new_emulator/bin/activate
#bash download_climateset.sh || { echo "Failed to run download_climateset.sh"; exit 1; }
pip install -r requirements.txt || { echo "Failed to install requirements."; exit 1; }




echo $PYTHONPATH
dir
cd $(pwd)


export NCCL_BLOCKING_WAIT=1 #Pytorch Lightning uses the NCCL backend for inter-GPU communication by default. Set this variable to avoid timeout errors.


# 8. Run Python
export HYDRA_FULL_ERROR=1
echo "Running python test.py ..."
srun  python emulator/run.py experiment=superemulator/test_convlstm.yaml logger=tensorboard seed=3423


# 9. Copy output to scratch
#cp /home/mila/f/felix-andreas.nahrstedt/Slurm/SC6-basetest-convlstm_out.out 

# 10. Experiment is finished

echo "Experiment $EXP_NAME is concluded."